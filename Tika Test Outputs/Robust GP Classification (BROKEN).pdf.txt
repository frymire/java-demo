
Robust Multi-Class Gaussian Process Classification

Daniel Herna´ndez-Lobato
ICTEAM - Machine Learning Group

Universite´ catholique de Louvain
Place Sainte Barbe, 2

Louvain-La-Neuve, 1348, Belgium
danielhernandezlobato@gmail.com

Jose´ Miguel Herna´ndez-Lobato
Department of Engineering
University of Cambridge

Trumpington Street, Cambridge
CB2 1PZ, United Kingdom
jmh233@eng.cam.ac.uk

Pierre Dupont
ICTEAM - Machine Learning Group

Universite´ catholique de Louvain
Place Sainte Barbe, 2

Louvain-La-Neuve, 1348, Belgium
pierre.dupont@uclouvain.be

Abstract

Multi-class Gaussian Process Classifiers (MGPCs) are often affected by over-
fitting problems when labeling errors occur far from the decision boundaries. To
prevent this, we investigate a robust MGPC (RMGPC) which considers labeling
errors independently of their distance to the decision boundaries. Expectation
propagation is used for approximate inference. Experiments with several datasets
in which noise is injected in the labels illustrate the benefits of RMGPC. This
method performs better than other Gaussian process alternatives based on consid-
ering latent Gaussian noise or heavy-tailed processes. When no noise is injected in
the labels, RMGPC still performs equal or better than the other methods. Finally,
we show how RMGPC can be used for successfully identifying data instances
which are difficult to classify correctly in practice.

1 Introduction

Multi-class Gaussian process classifiers (MGPCs) are a Bayesian approach to non-parametric multi-
class classification with the advantage of producing probabilistic outputs that measure uncertainty
in the predictions [1]. MGPCs assume that there are some latent functions (one per class) whose
value at a certain location is related by some rule to the probability of observing a specific class
there. The prior for each of these latent functions is specified to be a Gaussian process. The task of
interest is to make inference about the latent functions using Bayes’ theorem. Nevertheless, exact
Bayesian inference in MGPCs is typically intractable and one has to rely on approximate methods.
Approximate inference can be implemented using Markov-chain Monte Carlo sampling, the Laplace
approximation or expectation propagation [2, 3, 4, 5].

A problem of MGPCs is that, typically, the assumed rule that relates the values of the latent functions
with the different classes does not consider the possibility of observing errors in the labels of the
data, or at most, only considers the possibility of observing errors near the decision boundaries
of the resulting classifier [1]. The consequence is that over-fitting can become a serious problem
when errors far from these boundaries are observed in practice. A notable exception is found in
the binary classification case when the labeling rule suggested in [6] is used. Such rule considers
the possibility of observing errors independently of their distance to the decision boundary [7, 8].
However, the generalization of this rule to the multi-class case is difficult. Existing generalizations

1



are in practice simplified so that the probability of observing errors in the labels is zero [3]. Labeling
errors in the context of MGPCs are often accounted for by considering that the latent functions of the
MGPC are contaminated with additive Gaussian noise [1]. Nevertheless, this approach has again the
disadvantage of considering only errors near the decision boundaries of the resulting classifier and is
expected to lead to over-fitting problems when errors are actually observed far from the boundaries.
Finally, some authors have replaced the underlying Gaussian processes of the MGPC with heavy-
tailed processes [9]. These processes have marginal distributions with heavier tails than those of a
Gaussian distribution and are in consequence expected to be more robust to labeling errors far from
the decision boundaries.

In this paper we investigate a robust MGPC (RMGPC) that addresses labeling errors by introducing
a set of binary latent variables. One latent variable for each data instance. These latent variables
indicate whether the assumed labeling rule is satisfied for the associated instances or not. If such
rule is not satisfied for a given instance, we consider that the corresponding label has been randomly
selected with uniform probability among the possible classes. This is used as a back-up mechanism
to explain data instances that are highly unlikely to stem from the assumed labeling rule. The
resulting likelihood function depends only on the total number of errors, and not on the distances
of these errors to the decision boundaries. Thus, RMGPC is expected to be fairly robust when
the data contain noise in the labels. In this model, expectation propagation (EP) can be used to
efficiently carry out approximate inference [10]. The cost of EP is O(ln3), where n is the number
of training instances and l is the number of different classes. RMGPC is evaluated in four datasets
extracted from the UCI repository [11] and from other sources [12]. These experiments show the
beneficial properties of the proposed model in terms of prediction performance. When labeling noise
is introduced in the data, RMGPC outperforms other MGPC approaches based on considering latent
Gaussian noise or heavy-tailed processes. When there is no noise in the data, RMGPC performs
better or equivalent to these alternatives. Extra experiments also illustrate the utility of RMGPC to
identify data instances that are unlikely to stem from the assumed labeling rule.

The organization of the rest of the manuscript is as follows: Section 2 introduces the RMGPC model.
Section 3 describes how expectation propagation can be used for approximate Bayesian inference.
Then, Section 4 evaluates and compares the predictive performance of RMGPC. Finally, Section 5
summarizes the conclusions of the investigation.

2 Robust Multi-Class Gaussian Process Classification

Consider n training instances in the form of a collection of feature vectors X = {x1, . . . ,xn} with
associated labels y = {y1, . . . , yn}, where yi ? C = {1, . . . , l} and l is the number of classes. We
follow [3] and assume that, in the noise free scenario, the predictive rule for yi given xi is

yi = arg max
k

fk(xi) , (1)

where f1, . . . , fl are unknown latent functions that have to be estimated. The prediction rule given by
(1) is unlikely to hold always in practice. For this reason, we introduce a set of binary latent variables
z = {z1, . . . , zn}, one per data instance, to indicate whether (1) is satisfied (zi = 0) or not (zi = 1).
In this latter case, the pair (xi, yi) is considered to be an outlier and, instead of assuming that yi is
generated by (1), we assume that xi is assigned a random class sampled uniformly from C. This is
equivalent to assuming that f1, . . . , fl have been contaminated with an infinite amount of noise and
serves as a back-up mechanism to explain observations which are highly unlikely to originate from
(1). The likelihood function for f = (f1(x1), f1(x2) . . . , f1(xn), f2(x1), f2(x2) . . . , f2(xn), . . . ,
fl(x1), fl(x2), . . . , fl(xn))

T given y, X and z is

P(y|X, z, f) =
n?
i=1

???
k 6=yi

?(fyi(xi)? fk(xi))
??1?zi [1

l

]zi
, (2)

where ?(·) is the Heaviside step function. In (2), the contribution to the likelihood of each instance
(xi, yi) is a a mixture of two terms: A first term equal to

?
k 6=yi ?(fyi(xi)? fk(xi)) and a second

term equal to 1/l. The mixing coefficient is the prior probability of zi = 1. Note that only the first
term actually depends on the accuracy of f . In particular, it takes value 1 when the corresponding
instance is correctly classified using (1) and 0 otherwise. Thus, the likelihood function described in

2



(2) considers only the total number of prediction errors made by f and not the distance of these errors
to the decision boundary. The consequence is that (2) is expected to be robust when the observed
data contain labeling errors far from the decision boundaries.

We do not have any preference for a particular instance to be considered an outlier. Thus, z is set to
follow a priori a factorizing multivariate Bernoulli distribution:

P(z|?) = Bern(z|?) =
n?
i=1

?zi(1? ?)1?zi , (3)

where ? is the prior fraction of training instances expected to be outliers. The prior for ? is set to be
a conjugate beta distribution, namely

P(?) = Beta(?|a0, b0) = ?
a0?1(1? ?)b0?1

B(a0, b0)
, (4)

where B(·, ·) is the beta function and a0 and b0 are free hyper-parameters. The values of a0 and b0
do not have a big impact on the final model provided that they are consistent with the prior belief
that most of the observed data are labeled using (1) (b0 > a0) and that they are small such that (4) is
not too constraining. We suggest a0 = 1 and b0 = 9.

As in [3], the prior for f1, . . . , fl is set to be a product of Gaussian processes with means equal to 0
and covariance matrices K1, . . . ,Kl, as computed by l covariance functions c1(·, ·), . . . , cl(·, ·):

P(f) =
l?

k=1

N (fk|0,Kk) (5)

whereN (·|µ,?) denotes a multivariate Gaussian density with mean vectorµ and covariance matrix
?, f is defined as in (2) and fk = (fk(x1), fk(x2), . . . , fk(xn))T, for k = 1, . . . , l.

2.1 Inference, Prediction and Outlier Identification

Given the observed data X and y, we make inference about f , z and ? using Bayes’ theorem:

P(?, z, f |y,X) = P(y|X, z, f)P(z|?)P(?)P(f)P(y|X) , (6)
where P(y|X) is the model evidence, a constant useful to perform model comparison under a
Bayesian setting [13]. The posterior distribution and the likelihood function can be used to compute
a predictive distribution for the label y? ? C associated to a new observation x?:

P(y?|x?,y,X) =
?
z ,z?

?
P(y?|x?, z?, f?)P(z?|?)P(f?|f)P(?, z, f |y,X) df df? d? , (7)

where f? = (f1(x?), . . . , fl(x?))T, P(y?|x?, z?, f?) =
?
k 6=y? ?(fk(x?) ? fy?(x?))1?z?(1/l)z? ,

P(z?|?) = ?z?(1? ?)1?z? and P(f?|f) is a product of l conditional Gaussians with zero mean and
covariance matrices given by the covariance functions of K1, . . . ,Kl. The posterior for z is

P(z|y,X) =
?
P(?, z, f |y,X)dfd? . (8)

This distribution is useful to compute the posterior probability that the i-th training instance is an
outlier, i.e., P(zi = 1|y,X). For this, we only have to marginalize (8) with respect to all the
components of z except zi. Unfortunately, the exact computation of (6), (7) and P(zi = 1|y,X) is
intractable for typical classification problems. Nevertheless, these expressions can be approximated
using expectation propagation [10].

3 Expectation Propagation

The joint probability of f , z, ? and y given X can be written as the product of l(n+ 1) + 1 factors:
P(f , z, ?,y|X) = P(y|X, z, f)P(z|?)P(?)P(f)

=

?? n?
i=1

?
k 6=yi

?ik(f , z, ?)

??[ n?
i=1

?i(f , z, ?)

]
??(f , z, ?)

[
l?

k=1

?k(f , z, ?)

]
, (9)

3



where each factor has the following form:

?ik(f , z, ?) = ?(fyi(xi)? fk(xi))1?zi(l?
1
l?1 )zi , ?i(f , z, ?) = ?

zi(1? ?)1?zi ,

??(f , z, ?) =
?a0?1(1? ?)b0?1

B(a0, b0)
, ?k(f , z, ?) = N (fk|0,Kk) . (10)

Let ? be the set that contains all these exact factors. Expectation propagation (EP) approximates
each ? ? ? using a corresponding simpler factor ?˜ such that?? n?

i=1

?
k 6=yi

?ik

??[ n?
i=1

?i

]
??

[
l?

k=1

?k

]
?
?? n?
i=1

?
k 6=yi

?˜ik

??[ n?
i=1

?˜i

]
?˜?

[
l?

k=1

?˜k

]
. (11)

In (11) the dependence of the exact and the approximate factors on f , z and ? has been removed
to improve readability. The approximate factors ?˜ are constrained to belong to the same family of
exponential distributions, but they do not have to integrate to one. Once normalized with respect to
f , z and ?, (9) becomes the exact posterior distribution (6). Similarly, the normalized product of the
approximate factors becomes an approximation to the posterior distribution:

Q(f , z, ?) = 1
Z

?? n?
i=1

?
k 6=yi

?˜ik(f , z, ?)

??[ n?
i=1

?˜i(f , z, ?)

]
?˜?(f , z, ?)

[
l?

k=1

?˜k(f , z, ?)

]
, (12)

whereZ is a normalization constant that approximatesP(y|X). Exponential distributions are closed
under product and division operations. Therefore, Q has the same form as the approximate factors
and Z can be readily computed. In practice, the form of Q is selected first, and the approximate
factors are then constrained to have the same form as Q. For each approximate factor ?˜ define
Q\?˜ ? Q/?˜ and consider the corresponding exact factor ?. EP iteratively updates each ?˜, one by
one, so that the Kullback-Leibler (KL) divergence between ?Q\?˜ and ?˜Q\?˜ is minimized. The EP
algorithm involves the following steps:

1. Initialize all the approximate factors ?˜ and the posterior approximationQ to be uniform.
2. Repeat untilQ converges:

(a) Select an approximate factor ?˜ to refine and computeQ\?˜ ? Q/?˜.
(b) Update the approximate factor ?˜ so that KL(?Q\?˜||?˜Q\?˜) is minimized.
(c) Update the posterior approximationQ to the normalized version of ?˜Q\?˜ .

3. Evaluate Z ? P(y|X) as the integral of the product of all the approximate factors.

The optimization problem in step 2-(b) is convex with a single global optimum. The solution to this
problem is found by matching sufficient statistics between ?Q\?˜ and ?˜Q\?˜ . EP is not guaranteed
to converge globally but extensive empirical evidence shows that most of the times it converges to
a fixed point [10]. Non-convergence can be prevented by damping the EP updates [14]. Damping
is a standard procedure and consists in setting ?˜ = [?˜new]?[?˜old]1?? in step 2-(b), where ?˜new is the
updated factor and ?˜old is the factor before the update. ? ? [0, 1] is a parameter which controls the
amount of damping. When ? = 1, the standard EP update operation is recovered. When ? = 0, no
update of the approximate factors occurs. In our experiments ? = 0.5 gives good results and EP
seems to always converge to a stationary solution. EP has shown good overall performance when
compared to other methods in the task of classification with binary Gaussian processes [15, 16].

3.1 The Posterior Approximation

The posterior distribution (6) is approximated by a distribution Q in the exponential family:

Q(f , z, ?) = Bern(z|p)Beta(?|a, b)
l?

k=1

N (fk|µk,?k) , (13)

where N (·|,µ,?) is a multivariate Gaussian distribution with mean µ and covariance matrix ?;
Beta(·|a, b) is a beta distribution with parameters a and b; and Bern(·|p) is a multivariate Bernoulli

4



distribution with parameter vector p. The parameters µk and ?k for k = 1, . . . , l and p, a and b
are estimated by EP. Note that Q factorizes with respect to fk for k = 1, . . . , l. This makes the cost
of the EP algorithm linear in l, the total number of classes. More accurate approximations can be
obtained at a cubic cost in l by considering correlations among the fk. The choice of (13) also makes
all the required computations tractable and provides good results in Section 4.

The approximate factors must have the same functional form as Q but they need not be normalized.
However, the exact factors ?ik with i = 1, . . . , n and k 6= yi, corresponding to the likelihood,
(2), only depend on fk(xi), fyi(xi) and zi. Thus, the beta part of the corresponding approximate
factors can be removed and the multivariate Gaussian distributions simplify to univariate Gaussians.
Specifically, the approximate factors ?˜ik with i = 1, . . . , n and k 6= yi are:

?˜ik(f , z, ?) = s˜ik exp

{
?1

2

[
(fk(xi)? µ˜ik)2

?˜ik
+

(fyi(xi)? µ˜yiik)2
?˜yiik

]}
p˜ziik(1? p˜ik)1?zi , (14)

where s˜ik, p˜ik, µ˜ik, ?˜ik, µ˜
yi
ik and ?˜

yi
ik are free parameters to be estimated by EP. Similarly, the exact

factors ?i, with i = 1, . . . , n, corresponding to the prior for the latent variables z, (3), only depend
on ? and zi. Thus, the Gaussian part of the corresponding approximate factors can be removed and
the multivariate Bernoulli distribution simplifies to a univariate Bernoulli. The resulting factors are:

?˜i(f , z, ?) = s˜i?
a˜i?1(1? ?)b˜i?1p˜zii (1? p˜i)1?zi , (15)

for i = 1, . . . , n, where s˜i, a˜i, b˜i, p˜i are free parameters to be estimated by EP. The exact factor ??
corresponding to the prior for ?, (4), need not be approximated, i.e., ?˜? = ??. The same applies to
the exact factors ?k, for k = 1, . . . , l, corresponding to the priors for f1, . . . , fl, (5). We set ?˜k = ?k
for k = 1, . . . , l. All these factors ?˜? and ?˜k, for k = 1, . . . , l, need not be refined by EP.

3.2 The EP Update Operations

The approximate factors ?˜ik, for i = 1, . . . , n and k 6= yi, corresponding to the likelihood, are
refined in parallel, as in [17]. This notably simplifies the EP updates. In particular, for each ?˜ik
we compute Q\?˜ik as in step 2-(a) of EP. Given each Q\?˜ik and the exact factor ?ik, we update
each ?˜ik. Then, Qnew is re-computed as the normalized product of all the approximate factors.
Preliminary experiments indicate that parallel and sequential updates converge to the same solution.
The remaining factors, i.e., ?˜i, for i = 1, . . . , n, are updated sequentially, as in standard EP. Further
details about all these EP updates are found in the supplementary material1. The cost of EP, assuming
constant iterations until convergence, isO(ln3). This is the cost of inverting l matrices of size n×n.

3.3 Model Evidence, Prediction and Outlier Identification

Once EP has converged, we can evaluate the approximation to the model evidence as the integral of
the product of all the approximate terms. This gives the following result:

logZ = B +

[
n?
i=1

logDi

]
+

1

2

[
l?

k=1

Ck ? log |Mk|
]

+

?? n?
i=1

???
k 6=yi

log s˜ik

??+ log s˜i
?? , (16)

where

Di = p˜i

???
k 6=yi

p˜ik

??+ (1? p˜i)
???
k 6=yi

(1? p˜ik)
?? , Ck = µTk??1k µk ? n?

i=1

?ki ,

?ki =

{?
k 6=yi(µ˜

yi
ik)

2/?˜yiik if k = yi ,
µ˜2ik/?˜ik otherwise ,

B = log B(a, b)? log B(a0, b0) , (17)

and Mk = ?kKk + I, with ?k a diagonal matrix defined as ?kii =
?
k 6=yi(?˜

yi
ik )
?1, if yi = k, and

?kii = ?˜
?1
ik otherwise. It is possible to compute the gradient of logZ with respect to ?kj , i.e., the j-th

1The supplementary material is available online at http://arantxa.ii.uam.es/%7edhernan/RMGPC/.

5



hyper-parameter of the k-th covariance function used to compute Kk. Such gradient is useful to find
the covariance functions ck(·, ·), with k = 1, . . . , l, that maximize the model evidence. Specifically,
one can show that, if EP has converged, the gradient of the free parameters of the approximate
factors with respect to ?kj is zero [18]. Thus, the gradient of logZ with respect to ?kj is

? logZ

??kj
= ?1

2
trace

(
M?1k ?

k ?Kk
??kj

)
+

1

2
(?k)T(M?1k )

T ?Kk
??kj

M?1k ?
k , (18)

where ?k = (bk1 , b
k
2 , . . . , b

k
n)

T with bki =
?
k 6=yi µ˜

yi
ik/?˜

yi
ik , if k = yi, and b

k
i = µ˜ik/?˜ik otherwise.

The predictive distribution (7) can be approximated when the exact posterior is replaced by Q:

P(y?|x?,y,X) ? ?
l

+ (1? ?)
?
N (u|my? , vy?)

?
k 6=y?

?

(
u?mk?

vk

)
du , (19)

where ?(·) is the cumulative probability function of a standard Gaussian distribution and
? = a/(a+ b) , mk = (k

?
k)

TK?1k Mk?
k , vk = ?

?
k ? (k?k)T

(
K?1k ?K?1k ?kK?1k

)
k?k , (20)

for k = 1, . . . , l, with k?k equal to the covariances between x? and X, and with ?
?
k equal to the

corresponding variance at x?, as computed by ck(·, ·). There is no closed form expression for the
integral in (19). However, it can be easily approximated by a one-dimensional quadrature.

The posterior (8) of z can be similarly approximated by marginalizing Q with respect to ? and f :

P(z|y,X) ? Bern(z|p) =
n?
i=1

[
pzii (1? pi)1?zi

]
, (21)

where p = (p1, . . . , pn)T. Each parameter pi of Q, with 1 ? i ? n, approximates P(zi = 1|y,X),
i.e., the posterior probability that the i-th training instance is an outlier. Thus, these parameters can
be used to identify the data instances that are more likely to be outliers.

The cost of evaluating (16) and (18) is respectively O(ln3) and O(n3). The cost of evaluating (19)
is O(ln2) since K?1k , with k = 1, . . . , l, needs to be computed only once.

4 Experiments

The proposed Robust Multi-class Gaussian Process Classifier (RMGPC) is compared in several ex-
periments with the Standard Multi-class Gaussian Process Classifier (SMGPC) suggested in [3].
SMGPC is a particular case of RMGPC which is obtained when b0 ? ?. This forces the prior
distribution for ?, (4), to be a delta centered at the origin, indicating that it is not possible to observe
outliers. SMGPC explains data instances for which (1) is not satisfied in practice by considering
Gaussian noise in the estimation of the functions f1, . . . , fl, which is the typical approach found
in the literature [1]. RMGPC is also compared in these experiments with the Heavy-Tailed Process
Classifier (HTPC) described in [9]. In HTPC, the prior for each latent function fk, with k = 1, . . . , l,
is a Gaussian Process that has been non-linearly transformed to have marginals that follow hyper-
bolic secant distributions with scale parameter bk. The hyperbolic secant distribution has heavier
tails than the Gaussian distribution and is expected to perform better in the presence of outliers.

4.1 Classification of Noisy Data

We carry out experiments on four datasets extracted from the UCI repository [11] and from other
sources [12] to evaluate the predictive performance of RMGPC, SMGPC and HTPC when different
fractions of outliers are present in the data2. These datasets are described in Table 1. All have
multiple classes and a fairly small number n of instances. We have selected problems with small n
because all the methods analyzed scale asO(n3). The data for each problem are randomly split 100
times into training and test sets containing respectively 2/3 and 1/3 of the data. Furthermore, the
labels of ? ? {0%, 5%, 10%, 20%} of the training instances are selected uniformly at random from
C. The data are normalized to have zero mean and unit standard deviation on the training set and

2The R source code of RMGPC is available at http://arantxa.ii.uam.es/%7edhernan/RMGPC/.

6



the average balanced class rate (BCR) of each method on the test set is reported for each value of
?. The BCR of a method with prediction accuracy ak on those instances of class k (k = 1, . . . , l) is
defined as 1/l

?l
k=1 ak. BCR is preferred to prediction accuracy in datasets with unbalanced class

distributions, which is the case for the datasets displayed in Table 1.

Table 1: Characteristics of the datasets used in the experiments.

Dataset # Instances # Attributes # Classes # Source
New-thyroid 215 5 3 UCI
Wine 178 13 3 UCI
Glass 214 9 6 UCI
SVMguide2 319 20 3 LIBSVM

In our experiments, the different methods analyzed (RMGPC, SMGPC and HTPC) use the same
covariance function for each latent function, i.e., ck(·, ·) = c(·, ·), for k = 1, . . . , l, where

c(xi,xj) = exp

{
? 1

2?
(xi ? xj)T (xi ? xj)

}
(22)

is a standard Gaussian covariance function with length-scale parameter ?. Preliminary experiments
on the datasets analyzed show no significant benefit from considering a different covariance function
for each latent function. The diagonal of the covariance matrices Kk, for k = 1, . . . , l, of SMGPC
are also added an extra term equal to ?2k to account for latent Gaussian noise with variance ?

2
k

around fk [1]. These extra terms are used by SMGPC to explain those instances that are unlikely
to stem from (1). In both RMGPC and SMGPC the parameter ? is found by maximizing (16) using
a standard gradient ascent procedure. The same method is used for tuning the parameters ?k in
SMGPC. In HTPC an approximation to the model evidence is maximized with respect to ? and the
scale parameters bk, with k = 1, . . . , l, using also gradient ascent [9].

Table 2: Average BCR in % of each method for each problem, as a function of ?.

Dataset RMGPC SMGPC HTPC RMGPC SMGPC HTPC
? = 0% ? = 5%

New-thyroid 94.2±4.5 93.9±4.4 90.0±5.5 C 92.7±4.9 90.7±5.8 C 89.7±6.1 C
Wine 98.0±1.6 98.0±1.6 97.3±2.0 C 97.5±1.7 97.3±2.0 96.6±2.2 C
Glass 65.2±7.7 60.6±8.6 C 59.5±8.0 C 63.5±8.0 58.9±8.0 C 57.9±7.5 C
SVMguide2 76.3±4.1 74.6±4.2 C 72.8±4.1 C 75.6±4.3 73.8±4.4 C 71.9±4.5 C

? = 10% ? = 20%
New-thyroid 92.3±5.4 89.0±5.5 C 88.3±6.6 C 89.5±6.0 85.9±7.4 C 85.7±7.7 C
Wine 97.0±2.2 96.4±2.6 95.6±4.6 C 96.6±2.7 95.5±2.6 C 95.1±3.0 C
Glass 63.9±7.9 58.0±7.4 C 55.7±7.7 C 59.7±8.3 55.5±7.3 C 52.8±7.8 C
SVMguide2 74.9±4.4 72.8±4.7 C 71.5±4.7 C 72.8±5.1 71.4±5.0 C 67.5±5.6 C

Table 2 displays for each problem the average BCR of each method for the different values of ?
considered. When the performance of a method is significantly different from the performance of
RMGPC, as estimated by a Wilcoxon rank test (p-value < 1%), the corresponding BCR is marked
with the symbolC. The table shows that, when there is no noise in the labels (i.e., ? = 0%), RMGPC
performs similarly to SMGPC in New-Thyroid and Wine, while it outperforms SMGPC in Glass
and SVMguide2. As the level of noise increases, RMGPC is found to outperform SMGPC in all the
problems investigated. HTPC typically performs worse than RMGPC and SMGPC independently of
the value of ?. This can be a consequence of HTPC using the Laplace approximation for approximate
inference [9]. In particular, there is evidence indicating that the Laplace approximation performs
worse than EP in the context of Gaussian process classifiers [15]. Extra experiments comparing
RMGPC, SMGPC and HTPC under 3 different noise scenarios appear in the supplementary material.
They further support the better performance of RMGPC in the presence of outliers in the data.

4.2 Outlier Identification

A second batch of experiments shows the utility of RMGPC to identify data instances that are likely
to be outliers. These experiments use the Glass dataset from the previous section. Recall that for this

7



dataset RMGPC performs significantly better than SMGPC for ? = 0%, which suggest the presence
of outliers. After normalizing the Glass dataset, we run RMGPC on the whole data and estimate the
posterior probability that each instance is an outlier using (21). The hyper-parameters of RMGPC
are estimated as described in the previous section. Figure 1 shows for each instance (xi, yi) of the
Glass dataset, with i = 1, . . . , n, the value of P(zi = 1|y,X). Note that most of the instances
are considered to be outliers with very low posterior probability. Nevertheless, there is a small set
of instances that have very high posterior probabilities. These instances are unlikely to stem from
(1) and are expected to be misclassified when placed on the test set. Consider the set of instances
that are more likely to be outliers than normal instances (i.e., instances 3, 36, 127, 137, 152, 158 and
188). Assume the experimental protocol of the previous section. Table 3 displays the fraction of
times that each of these instances is misclassified by RMGPC, SMGPC and HTPC when placed on
the test set. The posterior probability that each instance is an outlier, as estimated by RMGPC, is
also reported. The table shows that all the instances are typically misclassified by all the classifiers
investigated, which confirms the difficulty of obtaining accurate predictions for them in practice.

0 50 100 150 200

0.
00

0.
50

1.
00

Glass Data Instances

P
(z

_i
=

1|
y,

X
)

Figure 1: Posterior probability that each data instance form the Glass dataset is an outlier.

Table 3: Average test error in % of each method on each data instance that is more likely to be an
outlier. The probability that the instance is an outlier, as estimated by RMGPC, is also displayed.

Glass Data Instances
3-rd 36-th 127-th 137-th 152-th 158-th 188-th

Te
st

E
rr

or RMGPC 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0
SMGPC 100.0±0.0 92.0±5.5 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0
HTPC 100.0±0.0 84.0±7.5 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0 100.0±0.0

P(zi = 1|y,X) 0.69 0.96 0.82 0.51 0.86 0.83 1.00

5 Conclusions

We have introduced a Robust Multi-class Gaussian Process Classifier (RMGPC). RMGPC considers
only the number of errors made, and not the distance of such errors to the decision boundaries of
the classifier. This is achieved by introducing binary latent variables that indicate when a given
instance is considered to be an outlier (wrongly labeled instance) or not. RMGPC can also identify
the training instances that are more likely to be outliers. Exact Bayesian inference in RMGPC is
intractable for typical learning problems. Nevertheless, approximate inference can be efficiently
carried out using expectation propagation (EP). When EP is used, the training cost of RMGPC is
O(ln3), where l is the number of classes and n is the number of training instances. Experiments in
four multi-class classification problems show the benefits of RMGPC when labeling noise is injected
in the data. In this case, RMGPC performs better than other alternatives based on considering latent
Gaussian noise or noise which follows a distribution with heavy tails. When there is no noise in the
data, RMGPC performs better or equivalent to these alternatives. Our experiments also confirm the
utility of RMGPC to identify data instances that are difficult to classify accurately in practice. These
instances are typically misclassified by different predictors when included in the test set.

Acknowledgment

All experiments were run on the Center for Intensive Computation and Mass Storage (Louvain). All authors
acknowledge support from the Spanish MCyT (Project TIN2010-21575-C02-02).

8



References

[1] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine
Learning (Adaptive Computation and Machine Learning). The MIT Press, 2006.

[2] Christopher K. I. Williams and David Barber. Bayesian classification with Gaussian processes.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(12):1342–1351, 1998.

[3] Hyun-Chul Kim and Zoubin Ghahramani. Bayesian Gaussian process classification with
the EM-EP algorithm. IEEE Transactions on Pattern Analysis and Machine Intelligence,
28(12):1948–1959, 2006.

[4] R.M Neal. Regression and classification using Gaussian process priors. Bayesian Statistics,
6:475–501, 1999.

[5] Matthias Seeger and Michael I. Jordan. Sparse Gaussian process classification with multiple
classes. Technical report, University of California, Berkeley, 2004.

[6] M. Opper and O. Winther. Gaussian process classification and SVM: Mean field results. In
P. Bartlett, B.Schoelkopf, D. Schuurmans, and A. Smola, editors, Advances in large margin
classifiers, pages 43–65. MIT Press, 2000.

[7] Daniel Herna´ndez-Lobato and Jose´ Miguel Herna´ndez-Lobato. Bayes machines for binary
classification. Pattern Recognition Letters, 29(10):1466–1473, 2008.

[8] Hyun-Chul Kim and Zoubin Ghahramani. Outlier robust Gaussian process classification. In
Structural, Syntactic, and Statistical Pattern Recognition, volume 5342 of Lecture Notes in
Computer Science, pages 896–905. Springer Berlin / Heidelberg, 2008.

[9] Fabian L. Wauthier and Michael I. Jordan. Heavy-Tailed Process Priors for Selective Shrink-
age. In J. Lafferty, C. K. I. Williams, R. Zemel, J. Shawe-Taylor, and A. Culotta, editors,
Advances in Neural Information Processing Systems 23, pages 2406–2414. 2010.

[10] Thomas Minka. A Family of Algorithms for approximate Bayesian Inference. PhD thesis,
Massachusetts Institute of Technology, 2001.

[11] A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.
[12] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines, 2001.
[13] Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and

Statistics). Springer, August 2006.
[14] T. Minka and J. Lafferty. Expectation-propagation for the generative aspect model. In Adnan

Darwiche and Nir Friedman, editors, Proceedings of the 18th Conference on Uncertainty in
Artificial Intelligence, pages 352–359. Morgan Kaufmann, 2002.

[15] Malte Kuss and Carl Edward Rasmussen. Assessing approximate inference for binary Gaussian
process classification. Journal of Machine Learning Research, 6:1679–1704, 2005.

[16] H Nickisch and CE Rasmussen. Approximations for binary Gaussian process classification.
Journal of Machine Learning Research, 9:2035–2078, 10 2008.

[17] Marcel Van Gerven, Botond Cseke, Robert Oostenveld, and Tom Heskes. Bayesian source
localization with the multivariate Laplace prior. In Y. Bengio, D. Schuurmans, J. Lafferty,
C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems
22, pages 1901–1909, 2009.

[18] Matthias Seeger. Expectation propagation for exponential families. Technical report, Depart-
ment of EECS, University of California, Berkeley, 2006.

9


